{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'opacus' already exists and is not an empty directory.\n",
      "Obtaining file:///home/jaszy/opacus\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (1.18.5)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (1.4.0)\n",
      "Requirement already satisfied: torchvision>=0.4 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.40 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (4.48.2)\n",
      "Requirement already satisfied: scipy>=1.2 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (1.5.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (6.0.2)\n",
      "Requirement already satisfied: torchcsprng>=0.1.2 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (0.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.4->opacus==0.10.0) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.4->opacus==0.10.0) (8.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (20.2.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (1.0.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (8.5.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (20.4)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (1.9.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (1.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest->opacus==0.10.0) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->opacus==0.10.0) (3.1.0)\n",
      "Installing collected packages: opacus\n",
      "  Attempting uninstall: opacus\n",
      "    Found existing installation: opacus 0.10.0\n",
      "    Uninstalling opacus-0.10.0:\n",
      "      Successfully uninstalled opacus-0.10.0\n",
      "  Running setup.py develop for opacus\n",
      "Successfully installed opacus\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/opacus.git\n",
    "!cd opacus && pip install -e . --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opacus==0.10.0 in ./opacus (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (1.18.5)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (1.4.0)\n",
      "Requirement already satisfied: torchvision>=0.4 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.40 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (4.48.2)\n",
      "Requirement already satisfied: scipy>=1.2 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (1.5.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (6.0.2)\n",
      "Requirement already satisfied: torchcsprng>=0.1.2 in /opt/conda/lib/python3.7/site-packages (from opacus==0.10.0) (0.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.4->opacus==0.10.0) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.4->opacus==0.10.0) (8.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (20.2.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (1.0.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (8.5.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (20.4)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (1.9.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->opacus==0.10.0) (1.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest->opacus==0.10.0) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->opacus==0.10.0) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opacus==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-17 22:56:57--  https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.112.33\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.112.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1443490838 (1.3G) [application/zip]\n",
      "Saving to: ‘celeba.zip’\n",
      "\n",
      "celeba.zip          100%[===================>]   1.34G  6.72MB/s    in 92s     \n",
      "\n",
      "2020-11-17 22:58:30 (14.9 MB/s) - ‘celeba.zip’ saved [1443490838/1443490838]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nirooprsagar/privacyengine/pytorch-wgan\n"
     ]
    }
   ],
   "source": [
    "%cd pytorch-wgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
    "  zip_ref.extractall(\"data_faces/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202599\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root = '../data_faces/img_align_celeba'\n",
    "img_list = os.listdir(root)\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirooprsagar/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "from PIL import ImageFile\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\"\"\" data \"\"\"\n",
    "crop_size = 108\n",
    "re_size = 32\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.ToPILImage(),\n",
    "     transforms.Scale(size=(re_size, re_size), interpolation=Image.BICUBIC),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n",
    "\n",
    "batch_size = 16\n",
    "med_data = datasets.ImageFolder('../data_faces', transform=transform)\n",
    "data_loader = DataLoader(med_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import os\n",
    "from utils.tensorboard_logger import Logger\n",
    "from itertools import chain\n",
    "from torchvision import utils\n",
    "\n",
    "SAVE_PER_TIMES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # Filters [1024, 512, 256]\n",
    "        # Input_dim = 100\n",
    "        # Output_dim = C (number of channels)\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Z latent vector 100\n",
    "            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=1024),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (1024x4x4)\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (512x8x8)\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (256x16x16)\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=channels, kernel_size=4, stride=2, padding=1))\n",
    "            # output of main module --> Image (Cx32x32)\n",
    "\n",
    "        self.output = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_module(x)\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # Filters [256, 512, 1024]\n",
    "        # Input_dim = channels (Cx64x64)\n",
    "        # Output_dim = 1\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Image (Cx32x32)\n",
    "            nn.Conv2d(in_channels=channels, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State (256x16x16)\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State (512x8x8)\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "            # outptut of main module --> State (1024x4x4)\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0),\n",
    "            # Output 1\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_module(x)\n",
    "        return self.output(x)\n",
    "\n",
    "    def feature_extraction(self, x):\n",
    "        # Use discriminator for feature extraction then flatten to vector of 16384 features\n",
    "        x = self.main_module(x)\n",
    "        return x.view(-1, 1024*4*4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.module_modification import convert_batchnorm_modules\n",
    "\n",
    "DELTA = 1e-5\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self):\n",
    "        print(\"DCGAN model initalization.\")\n",
    "        self.G = Generator(3)\n",
    "        self.D = Discriminator(3)\n",
    "        self.C = 3\n",
    "        \n",
    "        #PrivacyEngine : Convert BatchNorm\n",
    "        \"\"\"\n",
    "        convert_batchnorm_modules(self.G)\n",
    "        convert_batchnorm_modules(self.D)\n",
    "        \"\"\"\n",
    "\n",
    "        # binary cross entropy loss and optimizer\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        self.cuda = False\n",
    "        self.cuda_index = 0\n",
    "        # check if cuda is available\n",
    "        self.check_cuda(True)\n",
    "\n",
    "        # Using lower learning rate than suggested by (ADAM authors) lr=0.0002  and Beta_1 = 0.5 instead od 0.9 works better [Radford2015]\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        #PrivacyEngine : Add Privacy engine to discriminator\n",
    "        privacy_engine = PrivacyEngine(\n",
    "          self.D,\n",
    "          batch_size * 2,\n",
    "          sample_size=len(data_loader.dataset),\n",
    "          alphas=[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)),\n",
    "          noise_multiplier=0.2,\n",
    "          max_grad_norm=1.0,\n",
    "        )\n",
    "        privacy_engine.attach(self.d_optimizer)\n",
    "\n",
    "        self.epochs = 30\n",
    "        self.batch_size = 16\n",
    "\n",
    "        # Set the logger\n",
    "        self.logger = Logger('./logs')\n",
    "        self.number_of_images = 10\n",
    "\n",
    "    # cuda support\n",
    "    def check_cuda(self, cuda_flag=False):\n",
    "        if cuda_flag:\n",
    "            self.cuda = True\n",
    "            self.D.cuda(self.cuda_index)\n",
    "            self.G.cuda(self.cuda_index)\n",
    "            self.loss = nn.BCELoss().cuda(self.cuda_index)\n",
    "            print(\"Cuda enabled flag: \")\n",
    "            print(self.cuda)\n",
    "\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        self.t_begin = t.time()\n",
    "        generator_iter = 0\n",
    "        #self.file = open(\"inception_score_graph.txt\", \"w\")\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for p in self.D.parameters():\n",
    "                if hasattr(p, \"grad_sample\"):\n",
    "                    del p.grad_sample\n",
    "            \n",
    "            self.epoch_start_time = t.time()\n",
    "\n",
    "            for i, (images, _) in enumerate(train_loader):\n",
    "                # Check if round number of batches\n",
    "                if i == train_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z = torch.rand((self.batch_size, 100, 1, 1))\n",
    "                real_labels = torch.ones(self.batch_size)\n",
    "                fake_labels = torch.zeros(self.batch_size)\n",
    "\n",
    "                if self.cuda:\n",
    "                    images, z = Variable(images).cuda(self.cuda_index), Variable(z).cuda(self.cuda_index)\n",
    "                    real_labels, fake_labels = Variable(real_labels).cuda(self.cuda_index), Variable(fake_labels).cuda(self.cuda_index)\n",
    "                else:\n",
    "                    images, z = Variable(images), Variable(z)\n",
    "                    real_labels, fake_labels = Variable(real_labels), Variable(fake_labels)\n",
    "\n",
    "\n",
    "                # Train discriminator\n",
    "                # Compute BCE_Loss using real images\n",
    "                outputs = self.D(images)\n",
    "                d_loss_real = self.loss(outputs.squeeze(), real_labels)\n",
    "                real_score = outputs\n",
    "\n",
    "                # Compute BCE Loss using fake images\n",
    "                if self.cuda:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "                else:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "                fake_images = self.G(z)\n",
    "                outputs = self.D(fake_images)\n",
    "                d_loss_fake = self.loss(outputs.squeeze(), fake_labels)\n",
    "                fake_score = outputs\n",
    "\n",
    "                # Optimize discriminator\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                self.D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Train generator\n",
    "                # Compute loss with fake images\n",
    "                if self.cuda:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "                else:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "                fake_images = self.G(z)\n",
    "                outputs = self.D(fake_images)\n",
    "                g_loss = self.loss(outputs.squeeze(), real_labels)\n",
    "\n",
    "                # Optimize generator\n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                generator_iter += 1\n",
    "\n",
    "\n",
    "                if generator_iter % 1000 == 0:\n",
    "                    print('Epoch-{}'.format(epoch + 1))\n",
    "                    self.save_model()\n",
    "\n",
    "                    if not os.path.exists('training_result_images/'):\n",
    "                        os.makedirs('training_result_images/')\n",
    "\n",
    "                    # Denormalize images and save them in grid 8x8\n",
    "                    z = Variable(torch.randn(800, 100, 1, 1)).cuda(self.cuda_index)\n",
    "                    samples = self.G(z)\n",
    "                    samples = samples.mul(0.5).add(0.5)\n",
    "                    samples = samples.data.cpu()[:64]\n",
    "                    grid = utils.make_grid(samples)\n",
    "                    utils.save_image(grid, 'training_result_images/img_generatori_iter_{}.png'.format(str(generator_iter).zfill(3)))\n",
    "\n",
    "                    time = t.time() - self.t_begin\n",
    "                    #print(\"Inception score: {}\".format(inception_score))\n",
    "                    print(\"Generator iter: {}\".format(generator_iter))\n",
    "                    print(\"Time {}\".format(time))\n",
    "\n",
    "                    # Write to file inception_score, gen_iters, time\n",
    "                    #output = str(generator_iter) + \" \" + str(time) + \" \" + str(inception_score[0]) + \"\\n\"\n",
    "                    #self.file.write(output)\n",
    "\n",
    "\n",
    "                if ((i + 1) % 100) == 0:\n",
    "                    epsilon, best_alpha = self.d_optimizer.privacy_engine.get_privacy_spent(DELTA)\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f, epsilon : %.2f \" %\n",
    "                          ((epoch + 1), (i + 1), train_loader.dataset.__len__() // self.batch_size, d_loss.data, g_loss.data, epsilon))\n",
    "\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1).cuda(self.cuda_index))\n",
    "\n",
    "                    # TensorBoard logging\n",
    "                    # Log the scalar values\n",
    "                    info = {\n",
    "                        'd_loss': d_loss.data,\n",
    "                        'g_loss': g_loss.data\n",
    "                    }\n",
    "                    \"\"\"\n",
    "\n",
    "                    for tag, value in info.items():\n",
    "                        self.logger.scalar_summary(tag, value, generator_iter)\n",
    "\n",
    "                    # Log values and gradients of the parameters\n",
    "                    for tag, value in self.D.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        self.logger.histo_summary(tag, self.to_np(value), generator_iter)\n",
    "                        self.logger.histo_summary(tag + '/grad', self.to_np(value.grad), generator_iter)\n",
    "                    \"\"\"\n",
    "                    # Log the images while training\n",
    "                    info = {\n",
    "                        'real_images': self.real_images(images, self.number_of_images),\n",
    "                        'generated_images': self.generate_img(z, self.number_of_images)\n",
    "                    }\n",
    "                    \"\"\"\n",
    "                    for tag, images in info.items():\n",
    "                        self.logger.image_summary(tag, images, generator_iter)\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "        self.t_end = t.time()\n",
    "        print('Time of training-{}'.format((self.t_end - self.t_begin)))\n",
    "        #self.file.close()\n",
    "\n",
    "        # Save the trained parameters\n",
    "        self.save_model()\n",
    "\n",
    "    def evaluate(self, test_loader, D_model_path, G_model_path):\n",
    "        self.load_model(D_model_path, G_model_path)\n",
    "        z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "        samples = self.G(z)\n",
    "        samples = samples.mul(0.5).add(0.5)\n",
    "        samples = samples.data.cpu()\n",
    "        grid = utils.make_grid(samples)\n",
    "        print(\"Grid of 8x8 images saved to 'dgan_model_image.png'.\")\n",
    "        utils.save_image(grid, 'dgan_model_image.png')\n",
    "\n",
    "    def real_images(self, images, number_of_images):\n",
    "        if (self.C == 3):\n",
    "            return self.to_np(images.view(-1, self.C, 32, 32)[:self.number_of_images])\n",
    "        else:\n",
    "            return self.to_np(images.view(-1, 32, 32)[:self.number_of_images])\n",
    "\n",
    "    def generate_img(self, z, number_of_images):\n",
    "        samples = self.G(z).data.cpu().numpy()[:number_of_images]\n",
    "        generated_images = []\n",
    "        for sample in samples:\n",
    "            if self.C == 3:\n",
    "                generated_images.append(sample.reshape(self.C, 32, 32))\n",
    "            else:\n",
    "                generated_images.append(sample.reshape(32, 32))\n",
    "        return generated_images\n",
    "\n",
    "    def to_np(self, x):\n",
    "        return x.data.cpu().numpy()\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.G.state_dict(), './generator.pkl')\n",
    "        torch.save(self.D.state_dict(), './discriminator.pkl')\n",
    "        print('Models save to ./generator.pkl & ./discriminator.pkl ')\n",
    "\n",
    "    def load_model(self, D_model_filename, G_model_filename):\n",
    "        D_model_path = os.path.join(os.getcwd(), D_model_filename)\n",
    "        G_model_path = os.path.join(os.getcwd(), G_model_filename)\n",
    "        self.D.load_state_dict(torch.load(D_model_path))\n",
    "        self.G.load_state_dict(torch.load(G_model_path))\n",
    "        print('Generator model loaded from {}.'.format(G_model_path))\n",
    "        print('Discriminator model loaded from {}-'.format(D_model_path))\n",
    "\n",
    "    def generate_latent_walk(self, number):\n",
    "        if not os.path.exists('interpolated_images/'):\n",
    "            os.makedirs('interpolated_images/')\n",
    "\n",
    "        # Interpolate between twe noise(z1, z2) with number_int steps between\n",
    "        number_int = 10\n",
    "        z_intp = torch.FloatTensor(1, 100, 1, 1)\n",
    "        z1 = torch.randn(1, 100, 1, 1)\n",
    "        z2 = torch.randn(1, 100, 1, 1)\n",
    "        if self.cuda:\n",
    "            z_intp = z_intp.cuda()\n",
    "            z1 = z1.cuda()\n",
    "            z2 = z2.cuda()\n",
    "\n",
    "        z_intp = Variable(z_intp)\n",
    "        images = []\n",
    "        alpha = 1.0 / float(number_int + 1)\n",
    "        print(alpha)\n",
    "        for i in range(1, number_int + 1):\n",
    "            z_intp.data = z1*alpha + z2*(1.0 - alpha)\n",
    "            alpha += alpha\n",
    "            fake_im = self.G(z_intp)\n",
    "            fake_im = fake_im.mul(0.5).add(0.5) #denormalize\n",
    "            images.append(fake_im.view(self.C,32,32).data.cpu())\n",
    "\n",
    "        grid = utils.make_grid(images, nrow=number_int )\n",
    "        utils.save_image(grid, 'interpolated_images/interpolated_{}.png'.format(str(number).zfill(3)))\n",
    "        print(\"Saved interpolated images to interpolated_images/interpolated_{}.\".format(str(number).zfill(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCGAN model initalization.\n",
      "Cuda enabled flag: \n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirooprsagar/privacyengine/opacus/opacus/privacy_engine.py:104: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
     ]
    },
    {
     "ename": "IncompatibleModuleException",
     "evalue": "Model contains incompatible modules.\nSome modules are not valid.: ['Main.main_module.3', 'Main.main_module.6']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompatibleModuleException\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6792fd3a4811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-762221cd9cb0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mprivacy_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/privacyengine/opacus/opacus/privacy_engine.py\u001b[0m in \u001b[0;36mattach\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         norm_clipper = (\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# pyre-fixme[6]: Expected `float` for 1st param but got\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/privacyengine/opacus/opacus/dp_model_inspector.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\n{inspector.message}: {inspector.violators}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompatibleModuleException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompatibleModuleException\u001b[0m: Model contains incompatible modules.\nSome modules are not valid.: ['Main.main_module.3', 'Main.main_module.6']"
     ]
    }
   ],
   "source": [
    "model = DCGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirooprsagar/privacyengine/opacus/opacus/privacy_engine.py:283: UserWarning: PrivacyEngine expected a batch of size 32 but the last step received a batch of size 16. This means that the privacy analysis will be a bit more pessimistic. You can set `drop_last = True` in your PyTorch dataloader to avoid this problem completely\n",
      "  f\"PrivacyEngine expected a batch of size {self.batch_size} \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 100/12662] D_loss: 2.02798605, G_loss: 0.32712087, epsilon : 76.22 \n",
      "Epoch: [ 1] [ 200/12662] D_loss: 1.45616984, G_loss: 0.47252500, epsilon : 76.42 \n",
      "Epoch: [ 1] [ 300/12662] D_loss: 1.71365547, G_loss: 0.43809110, epsilon : 76.61 \n",
      "Epoch: [ 1] [ 400/12662] D_loss: 1.61162186, G_loss: 0.40524542, epsilon : 76.80 \n",
      "Epoch: [ 1] [ 500/12662] D_loss: 1.43820059, G_loss: 0.51823080, epsilon : 77.00 \n",
      "Epoch: [ 1] [ 600/12662] D_loss: 1.79521370, G_loss: 0.39254099, epsilon : 77.19 \n",
      "Epoch: [ 1] [ 700/12662] D_loss: 1.37238622, G_loss: 0.48809907, epsilon : 77.39 \n",
      "Epoch: [ 1] [ 800/12662] D_loss: 2.11873889, G_loss: 0.34966341, epsilon : 77.58 \n",
      "Epoch: [ 1] [ 900/12662] D_loss: 1.85768461, G_loss: 0.38816872, epsilon : 77.78 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 1000\n",
      "Time 293.1992301940918\n",
      "Epoch: [ 1] [1000/12662] D_loss: 1.81388903, G_loss: 0.49903277, epsilon : 77.97 \n",
      "Epoch: [ 1] [1100/12662] D_loss: 1.92542672, G_loss: 0.37076175, epsilon : 78.17 \n",
      "Epoch: [ 1] [1200/12662] D_loss: 2.32704282, G_loss: 0.32252759, epsilon : 78.36 \n",
      "Epoch: [ 1] [1300/12662] D_loss: 1.80268168, G_loss: 0.40168536, epsilon : 78.56 \n",
      "Epoch: [ 1] [1400/12662] D_loss: 2.76862192, G_loss: 0.30184525, epsilon : 78.75 \n",
      "Epoch: [ 1] [1500/12662] D_loss: 1.36929202, G_loss: 0.52933407, epsilon : 78.95 \n",
      "Epoch: [ 1] [1600/12662] D_loss: 1.41089785, G_loss: 0.50176251, epsilon : 79.14 \n",
      "Epoch: [ 1] [1700/12662] D_loss: 1.12348855, G_loss: 0.51473033, epsilon : 79.33 \n",
      "Epoch: [ 1] [1800/12662] D_loss: 2.07630348, G_loss: 0.33914375, epsilon : 79.53 \n",
      "Epoch: [ 1] [1900/12662] D_loss: 1.70231724, G_loss: 0.42199779, epsilon : 79.72 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 2000\n",
      "Time 586.0742287635803\n",
      "Epoch: [ 1] [2000/12662] D_loss: 1.52726555, G_loss: 0.39044839, epsilon : 79.92 \n",
      "Epoch: [ 1] [2100/12662] D_loss: 1.36419177, G_loss: 0.49898610, epsilon : 80.11 \n",
      "Epoch: [ 1] [2200/12662] D_loss: 2.22538424, G_loss: 0.28723657, epsilon : 80.31 \n",
      "Epoch: [ 1] [2300/12662] D_loss: 1.58474946, G_loss: 0.50244129, epsilon : 80.50 \n",
      "Epoch: [ 1] [2400/12662] D_loss: 1.41468549, G_loss: 0.52655303, epsilon : 80.70 \n",
      "Epoch: [ 1] [2500/12662] D_loss: 1.19108248, G_loss: 0.71498251, epsilon : 80.89 \n",
      "Epoch: [ 1] [2600/12662] D_loss: 1.51620865, G_loss: 0.50201362, epsilon : 81.09 \n",
      "Epoch: [ 1] [2700/12662] D_loss: 1.49302578, G_loss: 0.61780524, epsilon : 81.28 \n",
      "Epoch: [ 1] [2800/12662] D_loss: 1.33010030, G_loss: 0.56748712, epsilon : 81.48 \n",
      "Epoch: [ 1] [2900/12662] D_loss: 1.56423044, G_loss: 0.50993997, epsilon : 81.67 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 3000\n",
      "Time 878.99542760849\n",
      "Epoch: [ 1] [3000/12662] D_loss: 2.47074270, G_loss: 0.33493835, epsilon : 81.86 \n",
      "Epoch: [ 1] [3100/12662] D_loss: 1.42940331, G_loss: 0.52279174, epsilon : 82.06 \n",
      "Epoch: [ 1] [3200/12662] D_loss: 1.24229407, G_loss: 0.38175839, epsilon : 82.25 \n",
      "Epoch: [ 1] [3300/12662] D_loss: 1.75207162, G_loss: 0.34380430, epsilon : 82.45 \n",
      "Epoch: [ 1] [3400/12662] D_loss: 1.48096538, G_loss: 0.53605235, epsilon : 82.64 \n",
      "Epoch: [ 1] [3500/12662] D_loss: 1.46491504, G_loss: 0.52834064, epsilon : 82.84 \n",
      "Epoch: [ 1] [3600/12662] D_loss: 1.80177951, G_loss: 0.42075747, epsilon : 83.03 \n",
      "Epoch: [ 1] [3700/12662] D_loss: 1.46882355, G_loss: 0.52057016, epsilon : 83.23 \n",
      "Epoch: [ 1] [3800/12662] D_loss: 3.07649708, G_loss: 0.26033524, epsilon : 83.42 \n",
      "Epoch: [ 1] [3900/12662] D_loss: 1.94759107, G_loss: 0.39084268, epsilon : 83.62 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 4000\n",
      "Time 1171.7756493091583\n",
      "Epoch: [ 1] [4000/12662] D_loss: 1.43190432, G_loss: 0.64659679, epsilon : 83.81 \n",
      "Epoch: [ 1] [4100/12662] D_loss: 1.59480405, G_loss: 0.49335426, epsilon : 84.01 \n",
      "Epoch: [ 1] [4200/12662] D_loss: 1.15563154, G_loss: 0.49632347, epsilon : 84.20 \n",
      "Epoch: [ 1] [4300/12662] D_loss: 1.74648905, G_loss: 0.46314755, epsilon : 84.40 \n",
      "Epoch: [ 1] [4400/12662] D_loss: 1.36862493, G_loss: 0.59013164, epsilon : 84.59 \n",
      "Epoch: [ 1] [4500/12662] D_loss: 1.72119141, G_loss: 0.44130293, epsilon : 84.78 \n",
      "Epoch: [ 1] [4600/12662] D_loss: 2.08160663, G_loss: 0.39295250, epsilon : 84.98 \n",
      "Epoch: [ 1] [4700/12662] D_loss: 1.62245607, G_loss: 0.46789950, epsilon : 85.17 \n",
      "Epoch: [ 1] [4800/12662] D_loss: 1.45726013, G_loss: 0.55088246, epsilon : 85.37 \n",
      "Epoch: [ 1] [4900/12662] D_loss: 1.25825596, G_loss: 0.62949467, epsilon : 85.56 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 5000\n",
      "Time 1464.2070271968842\n",
      "Epoch: [ 1] [5000/12662] D_loss: 1.44293284, G_loss: 0.42247242, epsilon : 85.76 \n",
      "Epoch: [ 1] [5100/12662] D_loss: 1.43085265, G_loss: 0.49438459, epsilon : 85.95 \n",
      "Epoch: [ 1] [5200/12662] D_loss: 3.68321276, G_loss: 0.27293801, epsilon : 86.15 \n",
      "Epoch: [ 1] [5300/12662] D_loss: 1.79244101, G_loss: 0.35745889, epsilon : 86.34 \n",
      "Epoch: [ 1] [5400/12662] D_loss: 1.57323718, G_loss: 0.43562096, epsilon : 86.54 \n",
      "Epoch: [ 1] [5500/12662] D_loss: 2.29463816, G_loss: 0.34917086, epsilon : 86.73 \n",
      "Epoch: [ 1] [5600/12662] D_loss: 2.02333999, G_loss: 0.38362491, epsilon : 86.93 \n",
      "Epoch: [ 1] [5700/12662] D_loss: 1.80866611, G_loss: 0.42529494, epsilon : 87.12 \n",
      "Epoch: [ 1] [5800/12662] D_loss: 1.10489595, G_loss: 0.78619182, epsilon : 87.31 \n",
      "Epoch: [ 1] [5900/12662] D_loss: 1.39620268, G_loss: 0.51995015, epsilon : 87.51 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 6000\n",
      "Time 1756.6676008701324\n",
      "Epoch: [ 1] [6000/12662] D_loss: 1.89841902, G_loss: 0.43458802, epsilon : 87.70 \n",
      "Epoch: [ 1] [6100/12662] D_loss: 1.36490488, G_loss: 0.44651467, epsilon : 87.90 \n",
      "Epoch: [ 1] [6200/12662] D_loss: 1.14297009, G_loss: 0.59734964, epsilon : 88.09 \n",
      "Epoch: [ 1] [6300/12662] D_loss: 1.18267941, G_loss: 0.75891697, epsilon : 88.29 \n",
      "Epoch: [ 1] [6400/12662] D_loss: 2.13674474, G_loss: 0.38354340, epsilon : 88.48 \n",
      "Epoch: [ 1] [6500/12662] D_loss: 1.53225291, G_loss: 0.48037791, epsilon : 88.68 \n",
      "Epoch: [ 1] [6600/12662] D_loss: 1.51923990, G_loss: 0.54504913, epsilon : 88.87 \n",
      "Epoch: [ 1] [6700/12662] D_loss: 1.76406467, G_loss: 0.35593760, epsilon : 89.07 \n",
      "Epoch: [ 1] [6800/12662] D_loss: 1.78001916, G_loss: 0.49925873, epsilon : 89.26 \n",
      "Epoch: [ 1] [6900/12662] D_loss: 2.73253059, G_loss: 0.33172965, epsilon : 89.46 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 7000\n",
      "Time 2049.470348596573\n",
      "Epoch: [ 1] [7000/12662] D_loss: 1.70830727, G_loss: 0.56335247, epsilon : 89.65 \n",
      "Epoch: [ 1] [7100/12662] D_loss: 1.17647052, G_loss: 0.59447742, epsilon : 89.84 \n",
      "Epoch: [ 1] [7200/12662] D_loss: 1.46737325, G_loss: 0.40704185, epsilon : 90.04 \n",
      "Epoch: [ 1] [7300/12662] D_loss: 1.67341030, G_loss: 0.47032028, epsilon : 90.23 \n",
      "Epoch: [ 1] [7400/12662] D_loss: 1.76272035, G_loss: 0.51914930, epsilon : 90.43 \n",
      "Epoch: [ 1] [7500/12662] D_loss: 1.62033260, G_loss: 0.48435885, epsilon : 90.62 \n",
      "Epoch: [ 1] [7600/12662] D_loss: 1.67391324, G_loss: 0.43163761, epsilon : 90.82 \n",
      "Epoch: [ 1] [7700/12662] D_loss: 1.08283877, G_loss: 0.67096210, epsilon : 91.01 \n",
      "Epoch: [ 1] [7800/12662] D_loss: 2.20947313, G_loss: 0.28582668, epsilon : 91.21 \n",
      "Epoch: [ 1] [7900/12662] D_loss: 1.56333578, G_loss: 0.47686550, epsilon : 91.40 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Generator iter: 8000\n",
      "Time 2342.341184616089\n",
      "Epoch: [ 1] [8000/12662] D_loss: 1.43136382, G_loss: 0.52437818, epsilon : 91.60 \n",
      "Epoch: [ 1] [8100/12662] D_loss: 2.06995869, G_loss: 0.36549553, epsilon : 91.79 \n",
      "Epoch: [ 1] [8200/12662] D_loss: 1.27387357, G_loss: 0.53450161, epsilon : 91.99 \n",
      "Epoch: [ 1] [8300/12662] D_loss: 1.05391049, G_loss: 0.78605479, epsilon : 92.18 \n",
      "Epoch: [ 1] [8400/12662] D_loss: 1.64767790, G_loss: 0.42691571, epsilon : 92.37 \n",
      "Epoch: [ 1] [8500/12662] D_loss: 1.43354475, G_loss: 0.62104201, epsilon : 92.57 \n",
      "Epoch: [ 1] [8600/12662] D_loss: 1.57052255, G_loss: 0.40974554, epsilon : 92.76 \n",
      "Epoch: [ 1] [8700/12662] D_loss: 2.10066295, G_loss: 0.38547260, epsilon : 92.96 \n",
      "Epoch: [ 1] [8800/12662] D_loss: 0.91584641, G_loss: 0.46931791, epsilon : 93.15 \n",
      "Epoch: [ 1] [8900/12662] D_loss: 1.62518859, G_loss: 0.47572008, epsilon : 93.35 \n",
      "Epoch-1\n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator iter: 9000\n",
      "Time 2634.478222131729\n",
      "Epoch: [ 1] [9000/12662] D_loss: 1.62373614, G_loss: 0.48769262, epsilon : 93.54 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-85f6af1b2279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-7c9b559f1179>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# Compute loss with fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA = 1e-5\n",
    "epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'PrivacyEngine' has no attribute '__file__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e44161b43cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopacus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mPrivacyEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'PrivacyEngine' has no attribute '__file__'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
